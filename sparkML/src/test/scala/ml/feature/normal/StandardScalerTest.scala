package ml.feature.normal

import org.apache.spark.ml.feature.StandardScaler
import util.SparkTools

/**
  * 归一化处理，将所有数据映射到统一尺度
  * 该方法是线性的变换，当某一维特征上具有非线性的分布时，还需要配合其它的特征预处理方法。
  * 均值方差归一化
  * StandardScaler处理的对象是每一列，也就是每一维特征，将特征标准化为单位标准差或是0均值，或是0均值单位标准差。
  */
object StandardScalerTest extends SparkTools {
  val ss = new StandardScaler()
    .setInputCol("features")
    .setOutputCol("ssFeatures")
    .setWithStd(true) //默认为真。将数据标准化到单位标准差。
    .setWithStd(false) //默认为假。是否变换为0均值。
    .fit(df)

  val res = ss.transform(df)
  res.show(10, truncate = false)
  /**
    * +---+--------------+------------------------------------------------------------+
    * |id |features      |ssFeatures                                                  |
    * +---+--------------+------------------------------------------------------------+
    * |0  |[1.0,0.5,-1.0]|[0.6546536707079771,0.09352195295828246,-0.6546536707079771]|
    * |1  |[2.0,1.0,1.0] |[1.3093073414159542,0.18704390591656492,0.6546536707079771] |
    * |2  |[4.0,10.0,2.0]|[2.6186146828319083,1.8704390591656492,1.3093073414159542]  |
    * +---+--------------+------------------------------------------------------------+
    */

}
